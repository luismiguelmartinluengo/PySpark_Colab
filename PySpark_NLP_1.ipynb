{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkSession = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|                text|\n",
      "+---+--------------------+\n",
      "|  1|Hola compañero, ¿...|\n",
      "|  2|Yo estoy bastante...|\n",
      "|  3|Vamos a hacer est...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sparkSession.createDataFrame([(1,'Hola compañero, ¿cómo estás?'),\n",
    "                                   (2, 'Yo estoy bastante bien, gracias'),\n",
    "                                   (3, 'Vamos a hacer este ejercicio de NLP')],\n",
    "                                schema = StructType([StructField('id', IntegerType(), True),\n",
    "                                                    StructField('text', StringType(), True)]))\n",
    "df.show()                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------------+-----------------------------------------------------------------------------+\n",
      "|id |text                               |document                                                                     |\n",
      "+---+-----------------------------------+-----------------------------------------------------------------------------+\n",
      "|1  |Hola compañero, ¿cómo estás?       |[{document, 0, 27, Hola compañero, ¿cómo estás?, {sentence -> 0}, []}]       |\n",
      "|2  |Yo estoy bastante bien, gracias    |[{document, 0, 30, Yo estoy bastante bien, gracias, {sentence -> 0}, []}]    |\n",
      "|3  |Vamos a hacer este ejercicio de NLP|[{document, 0, 34, Vamos a hacer este ejercicio de NLP, {sentence -> 0}, []}]|\n",
      "+---+-----------------------------------+-----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assemblerConfig = sparknlp.DocumentAssembler().setInputCol('text')\\\n",
    "                                            .setOutputCol('document')\n",
    "dfAssembled = assemblerConfig.transform(df)\n",
    "dfAssembled.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------------+-----------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id |text                               |document                                                                     |token                                                                                                                                                                                                                                                                                                           |\n",
      "+---+-----------------------------------+-----------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |Hola compañero, ¿cómo estás?       |[{document, 0, 27, Hola compañero, ¿cómo estás?, {sentence -> 0}, []}]       |[{token, 0, 3, Hola, {sentence -> 0}, []}, {token, 5, 13, compañero, {sentence -> 0}, []}, {token, 14, 14, ,, {sentence -> 0}, []}, {token, 16, 20, ¿cómo, {sentence -> 0}, []}, {token, 22, 26, estás, {sentence -> 0}, []}, {token, 27, 27, ?, {sentence -> 0}, []}]                                          |\n",
      "|2  |Yo estoy bastante bien, gracias    |[{document, 0, 30, Yo estoy bastante bien, gracias, {sentence -> 0}, []}]    |[{token, 0, 1, Yo, {sentence -> 0}, []}, {token, 3, 7, estoy, {sentence -> 0}, []}, {token, 9, 16, bastante, {sentence -> 0}, []}, {token, 18, 21, bien, {sentence -> 0}, []}, {token, 22, 22, ,, {sentence -> 0}, []}, {token, 24, 30, gracias, {sentence -> 0}, []}]                                          |\n",
      "|3  |Vamos a hacer este ejercicio de NLP|[{document, 0, 34, Vamos a hacer este ejercicio de NLP, {sentence -> 0}, []}]|[{token, 0, 4, Vamos, {sentence -> 0}, []}, {token, 6, 6, a, {sentence -> 0}, []}, {token, 8, 12, hacer, {sentence -> 0}, []}, {token, 14, 17, este, {sentence -> 0}, []}, {token, 19, 27, ejercicio, {sentence -> 0}, []}, {token, 29, 30, de, {sentence -> 0}, []}, {token, 32, 34, NLP, {sentence -> 0}, []}]|\n",
      "+---+-----------------------------------+-----------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizerConfig = Tokenizer().setInputCols(['document'])\\\n",
    "                                    .setOutputCol('token')\n",
    "tokenizerPipeline = Pipeline().setStages([tokenizerConfig])\n",
    "dfTokenized = tokenizerPipeline.fit(dfAssembled).transform(dfAssembled)\n",
    "dfTokenized.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------------+-----------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id |text                               |document                                                                     |token                                                                                                                                                                                                                                                                                                           |token_cleaned                                                                                                                                                                                                                |\n",
      "+---+-----------------------------------+-----------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |Hola compañero, ¿cómo estás?       |[{document, 0, 27, Hola compañero, ¿cómo estás?, {sentence -> 0}, []}]       |[{token, 0, 3, Hola, {sentence -> 0}, []}, {token, 5, 13, compañero, {sentence -> 0}, []}, {token, 14, 14, ,, {sentence -> 0}, []}, {token, 16, 20, ¿cómo, {sentence -> 0}, []}, {token, 22, 26, estás, {sentence -> 0}, []}, {token, 27, 27, ?, {sentence -> 0}, []}]                                          |[{token, 0, 3, Hola, {sentence -> 0}, []}, {token, 5, 13, compañero, {sentence -> 0}, []}, {token, 16, 20, ¿cómo, {sentence -> 0}, []}, {token, 22, 26, estás, {sentence -> 0}, []}, {token, 27, 27, ?, {sentence -> 0}, []}]|\n",
      "|2  |Yo estoy bastante bien, gracias    |[{document, 0, 30, Yo estoy bastante bien, gracias, {sentence -> 0}, []}]    |[{token, 0, 1, Yo, {sentence -> 0}, []}, {token, 3, 7, estoy, {sentence -> 0}, []}, {token, 9, 16, bastante, {sentence -> 0}, []}, {token, 18, 21, bien, {sentence -> 0}, []}, {token, 22, 22, ,, {sentence -> 0}, []}, {token, 24, 30, gracias, {sentence -> 0}, []}]                                          |[{token, 3, 7, estoy, {sentence -> 0}, []}, {token, 9, 16, bastante, {sentence -> 0}, []}, {token, 18, 21, bien, {sentence -> 0}, []}, {token, 24, 30, gracias, {sentence -> 0}, []}]                                        |\n",
      "|3  |Vamos a hacer este ejercicio de NLP|[{document, 0, 34, Vamos a hacer este ejercicio de NLP, {sentence -> 0}, []}]|[{token, 0, 4, Vamos, {sentence -> 0}, []}, {token, 6, 6, a, {sentence -> 0}, []}, {token, 8, 12, hacer, {sentence -> 0}, []}, {token, 14, 17, este, {sentence -> 0}, []}, {token, 19, 27, ejercicio, {sentence -> 0}, []}, {token, 29, 30, de, {sentence -> 0}, []}, {token, 32, 34, NLP, {sentence -> 0}, []}]|[{token, 0, 4, Vamos, {sentence -> 0}, []}, {token, 8, 12, hacer, {sentence -> 0}, []}, {token, 19, 27, ejercicio, {sentence -> 0}, []}, {token, 32, 34, NLP, {sentence -> 0}, []}]                                          |\n",
      "+---+-----------------------------------+-----------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordsCleanerConfig = StopWordsCleaner().setInputCols(['token'])\\\n",
    "                                        .setOutputCol('token_cleaned')\\\n",
    "                                        .setCaseSensitive(False)\\\n",
    "                                        .setStopWords([',', 'yo', 'a', 'este', 'de'])\n",
    "dfCleaned = wordsCleanerConfig.transform(dfTokenized)\n",
    "dfCleaned.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------------+----------------------------------+\n",
      "|id |text                               |final_token                       |\n",
      "+---+-----------------------------------+----------------------------------+\n",
      "|1  |Hola compañero, ¿cómo estás?       |[Hola, compañero, ¿cómo, estás, ?]|\n",
      "|2  |Yo estoy bastante bien, gracias    |[estoy, bastante, bien, gracias]  |\n",
      "|3  |Vamos a hacer este ejercicio de NLP|[Vamos, hacer, ejercicio, NLP]    |\n",
      "+---+-----------------------------------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finisherConfig = Finisher().setInputCols(['token_cleaned'])\\\n",
    "                            .setOutputCols(['final_token'])\\\n",
    "                            .setCleanAnnotations(True)\n",
    "dfFinished = finisherConfig.transform(dfCleaned)\n",
    "dfFinished.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------+---------------------------------------+\n",
      "|id |final_token                       |features                               |\n",
      "+---+----------------------------------+---------------------------------------+\n",
      "|1  |[Hola, compañero, ¿cómo, estás, ?]|(13,[3,5,6,9,10],[1.0,1.0,1.0,1.0,1.0])|\n",
      "|2  |[estoy, bastante, bien, gracias]  |(13,[2,4,7,11],[1.0,1.0,1.0,1.0])      |\n",
      "|3  |[Vamos, hacer, ejercicio, NLP]    |(13,[0,1,8,12],[1.0,1.0,1.0,1.0])      |\n",
      "+---+----------------------------------+---------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCountVector = dfFinished.select('id', 'final_token')\n",
    "countVectorizerConfig = CountVectorizer().setInputCol('final_token')\\\n",
    "                                        .setOutputCol('features')\n",
    "countVectorizedModel = countVectorizerConfig.fit(dfCountVector)\n",
    "dfCountVectorized = countVectorizedModel.transform(dfCountVector)\n",
    "dfCountVectorized.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------------+----------------------------------+\n",
      "|id |text                               |final_token                       |\n",
      "+---+-----------------------------------+----------------------------------+\n",
      "|1  |Hola compañero, ¿cómo estás?       |[Hola, compañero, ¿cómo, estás, ?]|\n",
      "|2  |Yo estoy bastante bien, gracias    |[estoy, bastante, bien, gracias]  |\n",
      "|3  |Vamos a hacer este ejercicio de NLP|[Vamos, hacer, ejercicio, NLP]    |\n",
      "+---+-----------------------------------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeLineComplete = Pipeline().setStages([assemblerConfig, tokenizerConfig, wordsCleanerConfig, finisherConfig])\n",
    "modelComplete = pipeLineComplete.fit(df)\n",
    "dfComplete = modelComplete.transform(df)\n",
    "dfComplete.show(truncate = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
