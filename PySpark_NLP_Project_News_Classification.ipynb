{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNL8iqXhDTvnW3esS9qGsos",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luismiguelmartinluengo/PySpark_Demos/blob/main/PySpark_NLP_Project_News_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practice Project - News Classification with Spark NLP\n",
        "\n",
        "##Scenario\n",
        "**\"GLOBAL NEWS\"** is a premier international broadcasting company, renowned for its comprehensive and reliable news coverage. With a commitment to journalistic integrity and a global perspective, GLOBAL NEWS delivers the latest updates across a variety of genres, including politics, economy, technology, sports, entertainment, health, and environment. This extensive network ensures a steady stream of news from every corner of the globe, the problem lies in identifying and segregating news into different genres.\n",
        "##Problem Statement:\n",
        "GLOBAL NEWS has reached out to your company to build a NLP Model that meets their requirements. GLOBAL NEWS aims to enhance its news broadcasting efficiency and accuracy by implementing a Natural Language Processing (NLP) model. This model will perform automated text classification on incoming news articles, accurately identifying their genres for faster and more efficient dissemination.\n",
        "\n",
        "##Tasks:\n"
      ],
      "metadata": {
        "id": "RwSmEnm2d62e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Set Up the Environment Using John Snow Labs Bashline"
      ],
      "metadata": {
        "id": "dYGypMFBed-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install --upgrade -q pyspark==3.5.5 spark-nlp==5.5.3 findspark\n",
        " !pip list | grep -E 'pyspark|spark-nlp'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNXz1ZKPecqK",
        "outputId": "9f1ddbd1-2333-44af-d1a1-00000c1ef326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pyspark                            3.5.5\n",
            "spark-nlp                          5.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Import the Required Libraries."
      ],
      "metadata": {
        "id": "cBkfUN6RI3xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "from pyspark.sql import SparkSession\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "dtOT9vRqIdV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Mount Your Google Drive to Access Files."
      ],
      "metadata": {
        "id": "N9S6prEEJBGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvwBYWX-JFWN",
        "outputId": "0b579771-a35f-49ca-da6b-97165a06398c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Start the Spark NLP Session."
      ],
      "metadata": {
        "id": "MFC9aUZyJOMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "findspark.init()\n",
        "sparkSession = SparkSession.builder.appName(\"Spark NLP\").master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "som6F8tgJQrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Access a specific directory in Google Drive, list all filenames in that directory, and print the total number of files along with the first five filenames."
      ],
      "metadata": {
        "id": "Xi9gHx6gKZ5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Access a specific directory in Google Drive, list all filenames in that directory, and print the total number of files along with the first five filenames.\n",
        "\n",
        "import os\n",
        "\n",
        "# Specify the directory path in Google Drive\n",
        "directory_path = '/content/drive/MyDrive/your_directory'  # Replace 'your_directory' with the actual directory name\n",
        "\n",
        "# Check if the directory exists\n",
        "if os.path.exists(directory_path):\n",
        "  filenames = os.listdir(directory_path)\n",
        "  total_files = len(filenames)\n",
        "\n",
        "  print(f\"Total number of files: {total_files}\")\n",
        "  print(\"First five filenames:\")\n",
        "  for i in range(min(5, total_files)):\n",
        "    print(filenames[i])\n",
        "\n",
        "else:\n",
        "  print(f\"Error: Directory '{directory_path}' not found.\")\n"
      ],
      "metadata": {
        "id": "NcqqfP5hJjgy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}